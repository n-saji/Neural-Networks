{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, num_classes=102):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 3)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels, indices, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = self.indices[idx]\n",
    "        img_path = os.path.join(self.image_dir, self.images[img_idx - 1])  # Adjust index for 1-based MATLAB indexing\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[img_idx - 1] - 1  # Adjust labels to 0-based indexing\n",
    "        return image, label\n",
    "\n",
    "# Load dataset files\n",
    "image_dir = \"./jpg\"\n",
    "labels_mat = scipy.io.loadmat(\"imagelabels.mat\")['labels'][0]\n",
    "split_mat = scipy.io.loadmat(\"setid.mat\")\n",
    "\n",
    "# Get splits\n",
    "train_indices = split_mat['trnid'][0]\n",
    "valid_indices = split_mat['valid'][0]\n",
    "test_indices = split_mat['tstid'][0]\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FlowerDataset(image_dir, labels_mat, train_indices, transform=train_transform)\n",
    "valid_dataset = FlowerDataset(image_dir, labels_mat, valid_indices, transform=test_transform)\n",
    "test_dataset = FlowerDataset(image_dir, labels_mat, test_indices, transform=test_transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:43<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7.1923 Acc: 0.0020\n",
      "Val Loss: 7109.2048 Acc: 0.0127\n",
      "Epoch 2/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:20<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.7133 Acc: 0.0157\n",
      "Val Loss: 9.2113 Acc: 0.0196\n",
      "Epoch 3/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:29<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.4679 Acc: 0.0157\n",
      "Val Loss: 4.4634 Acc: 0.0304\n",
      "Epoch 4/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:20<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.3435 Acc: 0.0284\n",
      "Val Loss: 4.3290 Acc: 0.0304\n",
      "Epoch 5/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:25<00:00,  9.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1984 Acc: 0.0333\n",
      "Val Loss: 4.1493 Acc: 0.0431\n",
      "Best Val Acc: 0.0431\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet34(num_classes=102).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(valid_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(valid_loader.dataset)\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_resnet34.pth')\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/3h_3p7yj55q5prg62hx26fx00000gn/T/ipykernel_6036/2834191714.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_resnet34.pth'))\n",
      "100%|██████████| 97/97 [05:33<00:00,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Test Set: [90, 36, 36, 36, 36, 36, 36, 36, 36, 57, 36, 78, 36, 36, 90, 36, 36, 36, 36, 90, 36, 36, 90, 78, 36, 90, 90, 36, 90, 36, 36, 36, 36, 36, 78, 90, 36, 57, 90, 36, 86, 36, 36, 7, 36, 78, 90, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 57, 36, 36, 36, 90, 36, 36, 84, 57, 90, 36, 36, 84, 90, 90, 36, 36, 90, 57, 36, 36, 36, 57, 57, 36, 90, 36, 90, 90, 36, 90, 84, 90, 36, 36, 55, 36, 36, 90, 90, 36, 36, 55, 57, 36, 36, 36, 90, 91, 84, 36, 36, 36, 36, 57, 36, 55, 90, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 14, 70, 70, 70, 86, 57, 14, 7, 14, 57, 78, 86, 90, 14, 7, 7, 70, 59, 7, 7, 78, 7, 78, 86, 14, 57, 78, 57, 7, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 7, 7, 36, 7, 14, 14, 7, 7, 78, 78, 7, 7, 7, 7, 78, 7, 7, 7, 7, 78, 78, 36, 7, 78, 86, 7, 7, 7, 7, 7, 7, 7, 7, 78, 7, 78, 7, 42, 7, 7, 86, 14, 78, 7, 36, 7, 14, 78, 86, 7, 7, 7, 7, 14, 78, 78, 86, 7, 78, 78, 7, 7, 86, 7, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 14, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 7, 84, 70, 78, 36, 14, 7, 55, 36, 70, 78, 36, 78, 57, 36, 36, 55, 70, 55, 84, 14, 36, 36, 90, 84, 57, 90, 55, 84, 36, 7, 55, 36, 7, 90, 36, 84, 57, 90, 57, 84, 57, 70, 7, 14, 90, 90, 57, 36, 36, 78, 57, 90, 90, 55, 55, 7, 84, 55, 36, 36, 90, 36, 55, 14, 57, 78, 70, 14, 14, 14, 14, 70, 14, 70, 7, 70, 70, 14, 46, 70, 70, 70, 70, 78, 14, 14, 70, 7, 70, 70, 70, 70, 70, 70, 14, 14, 70, 7, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 14, 14, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 14, 14, 90, 57, 36, 57, 36, 78, 78, 36, 86, 7, 86, 36, 36, 36, 36, 36, 36, 90, 36, 78, 57, 36, 36, 78, 7, 36, 90, 57, 36, 36, 36, 36, 36, 36, 36, 36, 59, 78, 36, 84, 36, 36, 17, 36, 91, 78, 78, 36, 36, 78, 59, 36, 78, 36, 90, 36, 36, 70, 70, 70, 70, 70, 70, 70, 7, 7, 14, 7, 14, 70, 70, 14, 14, 70, 70, 14, 7, 70, 14, 14, 70, 70, 14, 14, 14, 14, 7, 70, 70, 14, 70, 7, 70, 14, 70, 46, 14, 78, 14, 7, 78, 70, 14, 70, 7, 70, 46, 14, 7, 7, 90, 57, 14, 57, 36, 78, 57, 57, 57, 7, 78, 14, 14, 86, 86, 57, 86, 36, 36, 91, 36, 36, 90, 36, 90, 36, 36, 36, 36, 84, 36, 36, 36, 84, 90, 90, 36, 90, 90, 90, 90, 90, 90, 36, 90, 84, 57, 91, 36, 36, 78, 36, 36, 90, 36, 36, 91, 36, 84, 36, 90, 36, 36, 36, 36, 84, 36, 90, 84, 90, 90, 90, 90, 90, 36, 90, 90, 90, 36, 36, 78, 84, 36, 36, 70, 70, 7, 78, 70, 55, 86, 90, 57, 57, 57, 57, 14, 36, 36, 55, 57, 7, 78, 36, 36, 36, 36, 36, 55, 57, 57, 36, 90, 36, 36, 36, 36, 36, 70, 70, 70, 90, 36, 57, 36, 36, 36, 36, 55, 57, 90, 36, 57, 57, 7, 57, 90, 78, 70, 84, 70, 36, 70, 55, 90, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 78, 36, 36, 90, 36, 90, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 7, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 90, 36, 36, 90, 36, 36, 36, 36, 36, 36, 90, 90, 36, 36, 36, 36, 90, 78, 90, 36, 36, 36, 36, 36, 36, 91, 90, 84, 36, 90, 36, 90, 36, 36, 36, 36, 36, 36, 36, 57, 36, 36, 90, 78, 36, 36, 36, 36, 36, 57, 36, 36, 78, 90, 36, 42, 57, 36, 36, 57, 57, 36, 57, 36, 36, 36, 36, 78, 36, 78, 78, 90, 36, 36, 36, 36, 57, 57, 57, 57, 36, 78, 57, 57, 57, 36, 90, 36, 36, 36, 90, 90, 36, 36, 36, 90, 36, 36, 86, 36, 57, 78, 36, 36, 57, 57, 57, 57, 57, 36, 57, 90, 57, 88, 57, 78, 57, 57, 90, 57, 57, 57, 55, 90, 90, 36, 36, 36, 36, 36, 36, 36, 86, 36, 36, 36, 14, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 55, 55, 55, 55, 57, 57, 55, 57, 57, 55, 57, 57, 57, 57, 7, 55, 57, 55, 57, 57, 88, 57, 57, 57, 57, 70, 57, 14, 57, 57, 70, 57, 55, 57, 14, 57, 57, 70, 14, 78, 57, 36, 36, 36, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 78, 90, 36, 90, 36, 36, 91, 36, 36, 36, 36, 36, 90, 36, 36, 90, 7, 36, 90, 36, 36, 90, 90, 55, 57, 36, 36, 36, 36, 91, 36, 78, 36, 36, 36, 90, 57, 36, 36, 36, 90, 36, 36, 36, 36, 78, 25, 36, 78, 90, 90, 36, 90, 36, 90, 91, 84, 36, 90, 55, 84, 84, 55, 36, 36, 90, 36, 84, 84, 55, 55, 84, 36, 90, 84, 55, 55, 55, 84, 84, 90, 84, 84, 90, 90, 90, 84, 90, 84, 36, 90, 90, 90, 36, 36, 84, 84, 84, 84, 36, 84, 90, 57, 84, 84, 84, 90, 90, 90, 90, 36, 36, 36, 36, 90, 84, 84, 84, 84, 84, 84, 36, 55, 88, 36, 36, 90, 57, 90, 59, 57, 90, 57, 36, 90, 36, 36, 36, 90, 55, 90, 36, 90, 84, 36, 78, 7, 57, 90, 36, 36, 36, 90, 36, 36, 36, 90, 55, 90, 84, 90, 84, 55, 84, 36, 55, 36, 36, 55, 36, 90, 90, 57, 36, 57, 90, 84, 84, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 70, 36, 36, 36, 36, 36, 36, 78, 36, 55, 84, 36, 84, 36, 84, 84, 55, 84, 55, 55, 57, 36, 90, 36, 90, 84, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 84, 36, 36, 84, 84, 90, 84, 90, 36, 90, 90, 36, 36, 36, 90, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 84, 84, 36, 36, 36, 36, 36, 84, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 36, 36, 84, 90, 36, 36, 36, 36, 36, 36, 57, 84, 78, 36, 90, 36, 36, 36, 36, 36, 78, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 57, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 90, 36, 36, 36, 90, 78, 36, 84, 90, 36, 36, 36, 36, 90, 36, 91, 57, 90, 70, 57, 90, 90, 90, 57, 57, 36, 36, 78, 36, 7, 36, 90, 36, 36, 7, 57, 78, 36, 36, 36, 36, 14, 36, 36, 36, 7, 78, 36, 36, 36, 78, 36, 78, 36, 78, 36, 36, 36, 90, 36, 57, 36, 36, 90, 78, 55, 70, 70, 7, 88, 14, 70, 55, 70, 78, 14, 70, 57, 55, 55, 55, 55, 70, 14, 78, 90, 36, 55, 14, 57, 36, 14, 55, 55, 7, 84, 70, 55, 36, 36, 78, 78, 36, 36, 90, 7, 36, 84, 55, 55, 57, 90, 57, 55, 70, 70, 36, 57, 84, 78, 14, 70, 70, 84, 84, 70, 70, 55, 70, 70, 55, 70, 70, 55, 55, 84, 57, 55, 84, 84, 14, 90, 55, 70, 70, 55, 55, 84, 55, 78, 55, 55, 55, 70, 70, 36, 90, 57, 57, 55, 84, 90, 90, 36, 36, 57, 55, 57, 70, 7, 55, 55, 70, 70, 7, 70, 14, 14, 70, 70, 70, 70, 70, 7, 14, 70, 14, 70, 70, 70, 14, 70, 70, 70, 14, 70, 70, 7, 70, 70, 70, 14, 70, 14, 14, 46, 70, 14, 14, 14, 14, 36, 36, 59, 90, 14, 36, 90, 55, 86, 36, 36, 14, 36, 7, 7, 57, 57, 78, 70, 36, 36, 36, 55, 78, 55, 36, 36, 86, 57, 57, 70, 90, 78, 36, 90, 70, 57, 36, 36, 57, 90, 36, 7, 36, 70, 14, 55, 55, 57, 55, 90, 57, 55, 91, 57, 90, 36, 84, 57, 36, 88, 36, 57, 90, 36, 36, 70, 57, 14, 84, 57, 86, 90, 57, 70, 84, 36, 57, 57, 90, 36, 70, 57, 36, 57, 25, 36, 36, 14, 36, 70, 55, 57, 90, 59, 7, 90, 36, 55, 90, 90, 14, 57, 7, 55, 14, 55, 90, 84, 7, 55, 55, 55, 57, 57, 55, 55, 36, 55, 90, 90, 55, 55, 55, 55, 84, 84, 55, 55, 86, 55, 55, 57, 55, 55, 59, 55, 90, 84, 55, 55, 90, 57, 84, 55, 36, 36, 55, 55, 55, 55, 55, 36, 84, 57, 36, 55, 90, 55, 55, 55, 55, 90, 14, 55, 57, 55, 36, 90, 55, 84, 36, 90, 36, 55, 90, 55, 55, 57, 55, 57, 57, 55, 91, 36, 90, 90, 36, 36, 90, 90, 14, 90, 90, 90, 90, 90, 36, 36, 36, 90, 78, 57, 70, 46, 70, 70, 46, 70, 70, 57, 57, 14, 14, 57, 14, 14, 70, 7, 14, 14, 14, 14, 14, 70, 70, 70, 70, 55, 70, 70, 55, 57, 14, 14, 70, 46, 70, 14, 57, 70, 70, 70, 70, 55, 70, 14, 70, 70, 14, 70, 70, 70, 14, 70, 57, 14, 70, 57, 14, 14, 14, 70, 55, 55, 57, 57, 57, 55, 14, 70, 14, 14, 14, 14, 70, 14, 70, 14, 14, 55, 55, 14, 70, 55, 55, 55, 14, 88, 14, 57, 70, 55, 14, 70, 7, 70, 70, 57, 70, 14, 55, 57, 70, 70, 70, 70, 70, 57, 14, 57, 70, 70, 70, 70, 26, 14, 57, 70, 57, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 57, 14, 70, 70, 70, 70, 14, 14, 14, 55, 55, 14, 14, 70, 70, 70, 14, 14, 70, 70, 70, 70, 14, 57, 55, 70, 70, 57, 57, 7, 57, 70, 70, 14, 14, 70, 70, 70, 14, 70, 70, 57, 70, 7, 78, 70, 70, 70, 70, 70, 46, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 7, 70, 70, 70, 14, 46, 46, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 46, 46, 14, 14, 70, 7, 14, 14, 70, 70, 70, 46, 70, 46, 70, 46, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 46, 14, 70, 70, 70, 70, 70, 70, 14, 70, 14, 14, 14, 14, 46, 70, 36, 36, 78, 36, 36, 78, 78, 36, 78, 78, 36, 36, 78, 78, 36, 78, 36, 36, 78, 36, 78, 78, 36, 78, 36, 78, 36, 78, 36, 70, 70, 70, 7, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 14, 14, 70, 70, 70, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 14, 70, 36, 36, 36, 36, 36, 36, 36, 36, 36, 84, 36, 55, 36, 84, 84, 90, 57, 55, 90, 55, 36, 36, 84, 55, 55, 36, 57, 36, 36, 55, 36, 36, 36, 36, 36, 36, 36, 36, 84, 84, 36, 36, 36, 91, 36, 36, 36, 36, 36, 55, 90, 36, 55, 55, 36, 55, 36, 90, 36, 36, 55, 57, 55, 84, 90, 36, 36, 90, 36, 55, 36, 36, 84, 84, 90, 55, 36, 36, 84, 55, 36, 84, 36, 36, 36, 36, 55, 78, 90, 78, 36, 55, 36, 36, 36, 36, 36, 36, 36, 36, 84, 36, 36, 36, 57, 90, 84, 36, 55, 36, 36, 84, 91, 36, 55, 36, 90, 55, 36, 55, 55, 55, 84, 55, 36, 36, 36, 90, 36, 36, 36, 36, 84, 84, 36, 36, 36, 36, 36, 84, 55, 84, 36, 36, 36, 36, 84, 36, 36, 36, 91, 36, 36, 84, 90, 90, 36, 36, 55, 36, 36, 57, 55, 36, 36, 36, 36, 90, 57, 55, 36, 36, 55, 55, 36, 36, 36, 57, 36, 36, 57, 90, 36, 36, 78, 84, 36, 36, 36, 36, 84, 36, 36, 55, 36, 90, 36, 57, 90, 57, 84, 55, 55, 36, 36, 36, 55, 36, 84, 84, 36, 36, 84, 84, 36, 36, 84, 90, 36, 36, 57, 90, 36, 55, 84, 84, 36, 36, 36, 55, 36, 55, 36, 55, 84, 36, 36, 90, 36, 36, 36, 36, 36, 78, 78, 78, 78, 36, 78, 36, 78, 78, 78, 36, 78, 78, 78, 36, 78, 36, 78, 100, 70, 90, 7, 7, 57, 14, 57, 7, 25, 78, 100, 52, 57, 57, 25, 86, 57, 86, 90, 90, 90, 86, 36, 90, 57, 78, 7, 36, 7, 90, 36, 36, 25, 90, 36, 78, 78, 90, 7, 78, 86, 70, 70, 70, 57, 36, 88, 36, 70, 70, 57, 57, 57, 36, 70, 84, 70, 70, 70, 36, 55, 55, 70, 57, 70, 36, 70, 70, 70, 70, 70, 57, 70, 7, 84, 84, 36, 55, 57, 36, 84, 70, 70, 36, 7, 57, 70, 57, 70, 84, 14, 55, 70, 88, 14, 70, 55, 86, 14, 36, 70, 36, 36, 36, 36, 70, 90, 36, 36, 36, 84, 36, 70, 36, 70, 70, 70, 14, 7, 70, 70, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 70, 14, 70, 70, 14, 14, 7, 70, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 90, 36, 36, 36, 90, 78, 36, 90, 36, 36, 36, 36, 36, 90, 91, 84, 36, 55, 57, 55, 55, 57, 57, 55, 55, 55, 57, 55, 55, 55, 57, 57, 55, 57, 55, 55, 55, 55, 55, 55, 57, 57, 57, 55, 55, 55, 55, 55, 55, 55, 57, 55, 55, 55, 55, 55, 55, 55, 55, 57, 55, 55, 55, 55, 57, 55, 55, 57, 55, 55, 55, 55, 55, 55, 55, 57, 55, 55, 55, 55, 55, 57, 57, 55, 55, 55, 55, 55, 55, 55, 55, 57, 55, 57, 57, 57, 57, 55, 57, 55, 57, 55, 55, 55, 57, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 78, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 57, 57, 57, 55, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 55, 57, 57, 57, 57, 55, 57, 57, 57, 57, 55, 55, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 55, 55, 57, 55, 55, 55, 55, 57, 55, 55, 55, 55, 57, 57, 14, 14, 7, 14, 7, 14, 7, 7, 59, 14, 7, 7, 7, 7, 14, 7, 7, 7, 14, 7, 14, 7, 7, 7, 7, 14, 14, 14, 14, 86, 14, 14, 7, 7, 7, 7, 7, 7, 7, 7, 57, 7, 57, 57, 7, 7, 14, 86, 7, 7, 86, 7, 7, 7, 86, 7, 7, 7, 86, 7, 7, 7, 7, 7, 78, 86, 7, 7, 78, 7, 7, 42, 78, 7, 7, 7, 7, 7, 7, 7, 7, 14, 78, 7, 7, 7, 78, 7, 7, 7, 86, 7, 7, 7, 78, 7, 7, 7, 7, 7, 7, 14, 78, 7, 78, 78, 7, 7, 86, 86, 7, 7, 86, 7, 7, 86, 7, 78, 57, 7, 7, 86, 86, 86, 86, 7, 78, 86, 78, 7, 78, 7, 14, 78, 7, 7, 78, 36, 86, 78, 78, 36, 36, 36, 78, 36, 78, 78, 78, 78, 78, 86, 78, 78, 36, 36, 78, 36, 36, 7, 36, 86, 78, 78, 36, 7, 36, 36, 36, 57, 42, 36, 78, 36, 36, 36, 36, 86, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 36, 90, 78, 7, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 46, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 70, 14, 70, 70, 14, 7, 70, 36, 70, 70, 70, 14, 70, 14, 70, 7, 14, 7, 70, 70, 14, 70, 70, 70, 70, 14, 14, 14, 14, 70, 70, 70, 14, 70, 70, 70, 46, 46, 70, 70, 14, 14, 46, 14, 14, 7, 7, 70, 70, 70, 7, 14, 14, 7, 70, 70, 70, 70, 46, 78, 36, 78, 46, 78, 36, 78, 86, 86, 14, 14, 14, 70, 14, 70, 14, 70, 70, 70, 70, 46, 36, 70, 84, 84, 84, 90, 84, 90, 84, 84, 84, 90, 84, 91, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 90, 84, 84, 90, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 36, 36, 36, 90, 90, 36, 36, 36, 57, 36, 90, 90, 57, 78, 90, 36, 36, 36, 36, 90, 36, 36, 57, 7, 36, 14, 36, 90, 36, 36, 86, 90, 86, 14, 36, 7, 57, 90, 7, 70, 36, 36, 78, 78, 36, 36, 36, 36, 78, 36, 36, 36, 70, 36, 36, 36, 7, 36, 36, 78, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 78, 78, 36, 36, 78, 78, 36, 36, 36, 7, 36, 36, 36, 78, 36, 36, 36, 36, 36, 78, 78, 36, 36, 36, 36, 36, 36, 78, 36, 86, 78, 78, 78, 78, 36, 78, 36, 36, 36, 78, 78, 86, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 14, 70, 70, 70, 14, 70, 14, 70, 70, 14, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 84, 57, 57, 84, 90, 84, 84, 90, 55, 84, 70, 57, 90, 57, 84, 90, 78, 55, 90, 57, 36, 90, 84, 84, 55, 55, 90, 36, 84, 84, 90, 55, 84, 57, 84, 84, 84, 36, 84, 84, 84, 36, 84, 84, 90, 84, 84, 84, 90, 57, 36, 55, 90, 84, 55, 55, 84, 36, 84, 36, 84, 57, 36, 84, 36, 78, 84, 90, 90, 57, 90, 55, 84, 84, 84, 84, 36, 57, 84, 78, 36, 36, 7, 14, 7, 7, 78, 36, 36, 7, 7, 7, 78, 70, 78, 78, 78, 57, 14, 78, 90, 7, 57, 57, 36, 7, 36, 7, 78, 90, 14, 90, 55, 78, 57, 36, 42, 78, 36, 57, 57, 7, 7, 7, 14, 90, 36, 57, 14, 36, 78, 78, 78, 78, 55, 90, 57, 36, 57, 57, 36, 36, 86, 57, 57, 90, 25, 57, 36, 86, 36, 36, 7, 7, 36, 36, 7, 7, 78, 90, 78, 78, 78, 36, 36, 57, 36, 78, 36, 36, 57, 90, 7, 90, 57, 78, 78, 55, 90, 36, 36, 36, 90, 57, 36, 14, 86, 36, 36, 7, 36, 36, 55, 57, 7, 78, 90, 36, 7, 14, 36, 36, 78, 7, 7, 36, 78, 78, 7, 57, 90, 78, 36, 36, 36, 86, 55, 70, 7, 36, 91, 36, 36, 7, 78, 57, 90, 36, 36, 90, 7, 7, 36, 36, 7, 78, 91, 57, 36, 7, 36, 57, 57, 36, 57, 78, 86, 90, 90, 7, 57, 78, 36, 57, 90, 84, 90, 78, 88, 14, 57, 55, 14, 84, 90, 36, 36, 57, 14, 90, 78, 14, 14, 84, 55, 70, 84, 90, 36, 14, 14, 90, 57, 36, 57, 7, 7, 70, 36, 57, 14, 57, 57, 55, 55, 57, 57, 57, 90, 7, 55, 7, 57, 57, 70, 90, 90, 55, 7, 84, 70, 55, 55, 7, 57, 36, 86, 90, 70, 57, 84, 70, 55, 36, 57, 57, 57, 36, 70, 90, 14, 70, 7, 84, 14, 84, 86, 7, 7, 36, 7, 70, 55, 70, 55, 55, 7, 70, 55, 70, 55, 84, 55, 78, 57, 55, 36, 55, 78, 7, 55, 14, 7, 36, 14, 7, 7, 84, 14, 14, 86, 55, 90, 84, 84, 57, 70, 90, 14, 91, 90, 55, 57, 70, 70, 57, 70, 78, 84, 55, 7, 78, 36, 91, 90, 57, 14, 57, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 55, 91, 84, 36, 57, 90, 90, 36, 84, 36, 36, 91, 36, 84, 36, 36, 36, 36, 36, 78, 36, 36, 36, 90, 84, 78, 90, 84, 84, 84, 90, 84, 36, 90, 57, 84, 36, 90, 90, 90, 36, 90, 57, 36, 57, 90, 36, 90, 90, 36, 36, 36, 78, 84, 36, 90, 36, 90, 36, 36, 90, 36, 90, 36, 36, 36, 90, 36, 84, 84, 91, 36, 78, 36, 36, 57, 36, 57, 55, 84, 36, 36, 90, 7, 36, 90, 36, 36, 86, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 78, 88, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 57, 36, 36, 36, 78, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 90, 36, 36, 36, 36, 86, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 57, 90, 36, 36, 36, 36, 7, 36, 36, 36, 36, 36, 36, 36, 36, 36, 57, 36, 36, 36, 36, 57, 36, 78, 36, 36, 36, 36, 90, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 86, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 78, 90, 36, 36, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 57, 78, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 90, 36, 36, 36, 36, 36, 90, 36, 36, 78, 36, 36, 36, 86, 7, 90, 91, 78, 36, 36, 36, 78, 36, 90, 42, 36, 90, 90, 36, 90, 36, 36, 36, 78, 90, 90, 36, 36, 90, 36, 36, 84, 90, 36, 36, 14, 36, 36, 36, 90, 78, 36, 36, 7, 36, 78, 36, 36, 90, 36, 91, 78, 36, 36, 90, 36, 36, 36, 36, 36, 78, 90, 36, 78, 36, 90, 36, 36, 78, 36, 36, 90, 84, 36, 57, 36, 14, 7, 90, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 36, 90, 36, 36, 36, 36, 36, 36, 90, 36, 78, 7, 36, 90, 36, 36, 36, 36, 36, 36, 14, 36, 91, 90, 91, 36, 36, 36, 36, 36, 36, 36, 36, 90, 36, 36, 36, 36, 78, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 90, 90, 57, 36, 90, 90, 55, 55, 57, 90, 14, 55, 55, 55, 25, 55, 57, 57, 57, 55, 55, 57, 36, 90, 57, 36, 57, 57, 78, 91, 55, 90, 90, 90, 55, 55, 57, 90, 57, 36, 57, 55, 78, 55, 57, 84, 90, 57, 90, 14, 55, 36, 36, 55, 57, 55, 55, 55, 90, 55, 36, 57, 36, 42, 90, 78, 55, 57, 57, 55, 57, 57, 7, 57, 36, 57, 55, 55, 57, 55, 7, 57, 36, 55, 36, 78, 14, 14, 7, 7, 78, 86, 7, 78, 78, 14, 7, 14, 7, 7, 7, 7, 7, 86, 7, 7, 7, 7, 7, 14, 7, 14, 78, 78, 14, 14, 14, 70, 7, 7, 78, 36, 14, 36, 7, 14, 86, 78, 7, 14, 14, 14, 14, 14, 7, 70, 36, 7, 7, 14, 78, 7, 36, 14, 7, 86, 70, 78, 78, 7, 14, 7, 78, 36, 36, 86, 78, 78, 36, 7, 36, 78, 36, 78, 7, 7, 70, 78, 7, 7, 36, 7, 78, 86, 86, 7, 36, 78, 7, 7, 14, 14, 14, 14, 7, 7, 36, 14, 36, 78, 36, 7, 36, 70, 14, 78, 7, 36, 36, 36, 78, 14, 7, 14, 7, 86, 7, 14, 78, 7, 7, 36, 14, 7, 36, 36, 36, 78, 14, 78, 78, 46, 78, 70, 7, 7, 36, 14, 7, 78, 7, 36, 84, 36, 55, 90, 36, 36, 7, 36, 78, 90, 36, 36, 55, 90, 57, 36, 36, 90, 36, 84, 36, 57, 90, 90, 90, 36, 36, 36, 36, 90, 36, 57, 90, 36, 57, 36, 36, 90, 36, 90, 90, 36, 90, 84, 36, 84, 84, 84, 36, 90, 90, 36, 90, 36, 55, 36, 84, 78, 36, 36, 36, 36, 57, 57, 90, 36, 90, 90, 36, 36, 90, 90, 36, 57, 36, 90, 90, 36, 36, 36, 57, 90, 36, 84, 84, 90, 36, 90, 36, 57, 36, 84, 7, 88, 57, 14, 84, 59, 90, 14, 90, 36, 14, 57, 70, 70, 55, 55, 57, 70, 70, 55, 7, 36, 36, 55, 55, 70, 57, 90, 86, 57, 70, 84, 70, 57, 36, 7, 7, 70, 57, 55, 55, 57, 36, 57, 90, 14, 14, 86, 55, 70, 55, 57, 70, 36, 7, 90, 70, 55, 84, 55, 55, 36, 57, 90, 55, 86, 84, 36, 88, 7, 36, 36, 90, 36, 55, 57, 14, 57, 70, 36, 90, 84, 7, 57, 55, 57, 57, 55, 55, 7, 57, 7, 55, 55, 7, 14, 70, 36, 70, 84, 14, 57, 14, 36, 78, 90, 90, 84, 55, 7, 36, 7, 36, 78, 57, 36, 57, 36, 36, 7, 36, 90, 14, 36, 36, 78, 36, 36, 36, 90, 36, 78, 7, 36, 36, 36, 36, 36, 78, 57, 36, 57, 36, 90, 78, 57, 36, 36, 36, 57, 36, 36, 70, 36, 36, 57, 78, 7, 70, 7, 36, 14, 36, 36, 36, 36, 14, 36, 7, 90, 36, 90, 36, 78, 36, 36, 90, 57, 90, 84, 36, 90, 55, 90, 91, 84, 78, 90, 36, 36, 90, 36, 55, 91, 84, 90, 78, 84, 90, 90, 90, 55, 90, 90, 36, 84, 84, 90, 84, 90, 55, 43, 90, 90, 90, 55, 90, 57, 84, 90, 84, 90, 90, 90, 84, 90, 84, 90, 36, 90, 84, 84, 78, 36, 84, 90, 84, 84, 90, 84, 91, 84, 36, 84, 78, 84, 84, 84, 84, 90, 84, 84, 84, 84, 84, 84, 84, 36, 14, 90, 90, 36, 36, 36, 90, 7, 36, 36, 36, 90, 36, 36, 36, 36, 14, 36, 36, 36, 36, 36, 14, 36, 36, 90, 78, 36, 90, 36, 36, 36, 36, 36, 36, 36, 36, 36, 70, 90, 36, 90, 84, 36, 36, 90, 84, 36, 78, 84, 36, 84, 36, 36, 36, 84, 36, 84, 55, 57, 84, 36, 36, 90, 36, 84, 84, 90, 90, 84, 84, 90, 90, 91, 36, 90, 84, 84, 36, 36, 91, 84, 84, 36, 36, 84, 36, 57, 36, 84, 36, 36, 36, 84, 90, 57, 55, 36, 36, 36, 84, 84, 36, 36, 36, 36, 36, 36, 36, 55, 84, 84, 36, 84, 90, 57, 36, 36, 55, 90, 55, 36, 36, 84, 36, 36, 84, 55, 84, 36, 90, 84, 36, 55, 84, 57, 7, 91, 36, 84, 36, 84, 36, 36, 55, 84, 36, 84, 84, 57, 57, 84, 36, 36, 36, 36, 84, 36, 90, 55, 84, 84, 36, 84, 36, 36, 84, 90, 84, 84, 55, 90, 90, 36, 36, 36, 70, 57, 70, 70, 57, 7, 14, 70, 57, 70, 57, 70, 57, 100, 55, 70, 26, 14, 14, 14, 70, 70, 70, 14, 70, 57, 70, 70, 7, 14, 70, 70, 70, 70, 70, 70, 70, 14, 70, 70, 70, 70, 14, 70, 70, 57, 57, 70, 57, 7, 14, 70, 7, 70, 70, 70, 70, 14, 55, 70, 70, 70, 88, 55, 70, 14, 70, 70, 14, 70, 26, 70, 14, 14, 70, 70, 70, 57, 14, 70, 70, 70, 57, 70, 7, 57, 70, 57, 70, 46, 57, 70, 70, 70, 70, 14, 14, 7, 57, 26, 70, 70, 70, 70, 14, 14, 70, 70, 7, 70, 70, 88, 70, 26, 14, 7, 14, 70, 70, 70, 88, 7, 70, 70, 14, 70, 70, 70, 14, 14, 70, 70, 70, 70, 70, 70, 70, 7, 70, 14, 70, 55, 70, 70, 70, 14, 57, 70, 88, 7, 57, 70, 70, 70, 70, 14, 88, 70, 70, 14, 14, 55, 70, 70, 70, 70, 57, 70, 70, 14, 70, 7, 14, 55, 70, 70, 70, 57, 70, 78, 14, 14, 36, 70, 7, 7, 70, 57, 70, 14, 70, 70, 70, 70, 70, 70, 14, 7, 70, 70, 70, 46, 78, 70, 70, 70, 7, 55, 70, 14, 70, 14, 14, 70, 14, 14, 57, 14, 70, 57, 70, 14, 70, 14, 70, 14, 36, 36, 78, 84, 57, 36, 57, 36, 36, 78, 57, 86, 36, 90, 36, 57, 36, 36, 36, 57, 57, 57, 36, 26, 78, 78, 36, 36, 36, 36, 78, 57, 36, 78, 36, 57, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 78, 36, 90, 55, 36, 78, 90, 90, 57, 90, 57, 36, 36, 57, 57, 36, 84, 57, 57, 36, 57, 36, 86, 57, 57, 57, 57, 57, 90, 90, 91, 55, 84, 84, 84, 84, 36, 57, 57, 57, 57, 36, 55, 57, 57, 57, 57, 57, 90, 36, 90, 57, 57, 57, 57, 90, 90, 90, 91, 36, 90, 84, 84, 36, 36, 36, 91, 36, 57, 57, 90, 57, 57, 36, 57, 42, 36, 36, 57, 36, 91, 90, 36, 36, 36, 55, 90, 84, 90, 90, 90, 36, 78, 57, 36, 14, 36, 36, 36, 90, 36, 36, 90, 36, 36, 90, 84, 36, 90, 57, 90, 84, 90, 36, 90, 90, 57, 43, 90, 36, 36, 90, 36, 36, 78, 90, 90, 90, 36, 90, 36, 84, 7, 90, 84, 36, 36, 91, 36, 84, 36, 36, 90, 36, 84, 90, 36, 36, 36, 36, 36, 84, 36, 36, 36, 25, 57, 84, 36, 36, 36, 36, 36, 36, 36, 90, 84, 90, 90, 36, 36, 25, 36, 90, 36, 36, 36, 42, 36, 90, 36, 90, 36, 36, 36, 90, 84, 36, 84, 90, 36, 36, 78, 84, 36, 36, 84, 84, 84, 84, 36, 36, 36, 36, 90, 78, 90, 36, 57, 84, 84, 78, 55, 84, 90, 57, 90, 36, 90, 36, 36, 36, 57, 36, 84, 84, 55, 84, 57, 57, 70, 84, 55, 70, 90, 78, 90, 84, 84, 36, 55, 55, 84, 55, 90, 7, 70, 57, 55, 55, 84, 84, 84, 90, 90, 84, 84, 14, 88, 90, 84, 88, 70, 84, 55, 84, 84, 90, 55, 84, 55, 90, 57, 57, 55, 55, 55, 57, 14, 25, 84, 7, 84, 78, 36, 70, 90, 90, 7, 57, 55, 55, 90, 90, 36, 55, 84, 84, 90, 84, 36, 55, 90, 55, 84, 36, 84, 55, 55, 36, 55, 36, 7, 84, 36, 90, 84, 84, 86, 55, 84, 84, 70, 14, 55, 55, 84, 84, 70, 84, 84, 55, 84, 55, 36, 57, 55, 55, 43, 36, 36, 36, 90, 36, 57, 55, 55, 36, 55, 36, 57, 57, 36, 36, 84, 90, 78, 36, 43, 36, 55, 36, 90, 84, 57, 55, 55, 55, 57, 55, 90, 90, 36, 84, 90, 55, 57, 36, 57, 36, 55, 57, 55, 84, 36, 78, 36, 90, 36, 78, 84, 57, 14, 57, 57, 90, 57, 90, 78, 14, 14, 7, 36, 57, 57, 57, 42, 14, 90, 57, 14, 14, 57, 86, 57, 57, 78, 57, 57, 57, 14, 78, 57, 57, 7, 55, 36, 57, 59, 42, 86, 57, 14, 55, 36, 36, 70, 36, 57, 57, 78, 86, 90, 36, 7, 36, 57, 57, 14, 36, 90, 90, 36, 91, 91, 78, 90, 90, 90, 36, 90, 90, 90, 84, 84, 90, 36, 84, 36, 36, 90, 90, 36, 36, 36, 90, 90, 84, 36, 90, 90, 90, 36, 36, 91, 90, 90, 90, 36, 36, 84, 36, 90, 36, 36, 84, 90, 84, 36, 36, 90, 84, 91, 36, 36, 90, 84, 90, 36, 90, 91, 90, 26, 86, 36, 57, 57, 14, 86, 57, 57, 57, 55, 57, 55, 90, 36, 57, 57, 70, 57, 57, 78, 78, 57, 7, 14, 57, 14, 78, 57, 57, 57, 70, 14, 55, 14, 14, 70, 36, 57, 7, 70, 36, 57, 26, 88, 88, 57, 57, 88, 88, 70, 88, 26, 88, 14, 57, 57, 57, 59, 59, 26, 70, 57, 14, 88, 57, 57, 88, 57, 26, 90, 57, 57, 57, 59, 55, 57, 57, 57, 55, 57, 55, 57, 57, 57, 57, 57, 57, 55, 55, 57, 57, 57, 90, 55, 90, 57, 90, 90, 55, 55, 7, 57, 57, 57, 57, 57, 57, 90, 70, 78, 57, 14, 14, 70, 7, 7, 14, 57, 7, 57, 14, 57, 42, 57, 59, 7, 7, 57, 7, 7, 7, 14, 7, 14, 7, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_resnet34.pth'))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = predict(model, test_loader)\n",
    "print(\"Predictions on Test Set:\", test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
